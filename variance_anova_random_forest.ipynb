{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Voxel-Based Morphometry on Oasis dataset\n",
    "========================================\n",
    "\n",
    "This example uses Voxel-Based Morphometry (VBM) to study the relationship\n",
    "between aging and gray matter density.\n",
    "\n",
    "The data come from the `OASIS <http://www.oasis-brains.org/>`_ project.\n",
    "If you use it, you need to agree with the data usage agreement available\n",
    "on the website.\n",
    "\n",
    "It has been run through a standard VBM pipeline (using SPM8 and\n",
    "NewSegment) to create VBM maps, which we study here.\n",
    "\n",
    "Predictive modeling analysis: VBM bio-markers of aging?\n",
    "--------------------------------------------------------\n",
    "\n",
    "We run a standard SVM-ANOVA nilearn pipeline to predict age from the VBM\n",
    "data. We use only 100 subjects from the OASIS dataset to limit the memory\n",
    "usage.\n",
    "\n",
    "Note that for an actual predictive modeling study of aging, the study\n",
    "should be ran on the full set of subjects. Also, parameters such as the\n",
    "smoothing applied to the data and the number of features selected by the\n",
    "Anova step should be set by nested cross-validation, as they impact\n",
    "significantly the prediction score.\n",
    "\n",
    "Brain mapping with mass univariate\n",
    "-----------------------------------\n",
    "\n",
    "SVM weights are very noisy, partly because heavy smoothing is detrimental\n",
    "for the prediction here. A standard analysis using mass-univariate GLM\n",
    "(here permuted to have exact correction for multiple comparisons) gives a\n",
    "much clearer view of the important regions.\n",
    "\n",
    "____\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Oasis dataset\n",
    "-------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinchang/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py:2266: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-081962d4837f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Demented'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'group'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscan_filenames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_prefix = '/Volumes/Elements/OAS2_RAW_PART1/'\n",
    "image_postfix = 'RAW/mpr-1.nifti.img'\n",
    "scan_filenames = ['OAS2_0001_MR1',\n",
    "            'OAS2_0002_MR1',\n",
    "            'OAS2_0004_MR1',\n",
    "            'OAS2_0005_MR1',\n",
    "            'OAS2_0007_MR1',\n",
    "            'OAS2_0008_MR1',\n",
    "            'OAS2_0009_MR1',\n",
    "            'OAS2_0010_MR1',\n",
    "            'OAS2_0012_MR1',\n",
    "            'OAS2_0013_MR1',\n",
    "            'OAS2_0014_MR1',\n",
    "            'OAS2_0016_MR1',\n",
    "            'OAS2_0017_MR1',\n",
    "            'OAS2_0018_MR1',\n",
    "            'OAS2_0020_MR1',\n",
    "            'OAS2_0021_MR1',\n",
    "            'OAS2_0022_MR1',\n",
    "            'OAS2_0023_MR1',\n",
    "            'OAS2_0026_MR1',\n",
    "            'OAS2_0027_MR1',\n",
    "            'OAS2_0028_MR1',\n",
    "            'OAS2_0029_MR1',\n",
    "            'OAS2_0030_MR1',\n",
    "            'OAS2_0031_MR1',\n",
    "            'OAS2_0032_MR1',\n",
    "            'OAS2_0034_MR1',\n",
    "            'OAS2_0035_MR1',\n",
    "            'OAS2_0036_MR1',\n",
    "            'OAS2_0037_MR1',\n",
    "            'OAS2_0039_MR1',\n",
    "            'OAS2_0040_MR1',\n",
    "            'OAS2_0041_MR1',\n",
    "            'OAS2_0042_MR1',\n",
    "            'OAS2_0043_MR1',\n",
    "            'OAS2_0044_MR1',\n",
    "            'OAS2_0045_MR1',\n",
    "            'OAS2_0046_MR1',\n",
    "            'OAS2_0047_MR1',\n",
    "            'OAS2_0048_MR1',\n",
    "            'OAS2_0049_MR1',\n",
    "            'OAS2_0050_MR1',\n",
    "            'OAS2_0051_MR1',\n",
    "            'OAS2_0052_MR1',\n",
    "            'OAS2_0053_MR1',\n",
    "            'OAS2_0054_MR1',\n",
    "            'OAS2_0055_MR1',\n",
    "            'OAS2_0056_MR1',\n",
    "            'OAS2_0057_MR1',\n",
    "            'OAS2_0058_MR1',\n",
    "            'OAS2_0060_MR1',\n",
    "            'OAS2_0061_MR1',\n",
    "            'OAS2_0062_MR1',\n",
    "            'OAS2_0063_MR1',\n",
    "            'OAS2_0064_MR1',\n",
    "            'OAS2_0066_MR1',\n",
    "            'OAS2_0067_MR1',\n",
    "            'OAS2_0068_MR1',\n",
    "            'OAS2_0069_MR1',\n",
    "            'OAS2_0070_MR1',\n",
    "            'OAS2_0071_MR1',\n",
    "            'OAS2_0073_MR1',\n",
    "            'OAS2_0075_MR1',\n",
    "            'OAS2_0076_MR1',\n",
    "            'OAS2_0077_MR1',\n",
    "            'OAS2_0078_MR1',\n",
    "            'OAS2_0079_MR1',\n",
    "            'OAS2_0080_MR1',\n",
    "            'OAS2_0081_MR1',\n",
    "            'OAS2_0085_MR1',\n",
    "            'OAS2_0086_MR1',\n",
    "            'OAS2_0087_MR1',\n",
    "            'OAS2_0088_MR1',\n",
    "            'OAS2_0089_MR1',\n",
    "            'OAS2_0090_MR1',\n",
    "            'OAS2_0091_MR1',\n",
    "            'OAS2_0092_MR1',\n",
    "            'OAS2_0094_MR1',\n",
    "            'OAS2_0095_MR1',\n",
    "            'OAS2_0096_MR1',\n",
    "            'OAS2_0097_MR1',\n",
    "            'OAS2_0098_MR1',\n",
    "            'OAS2_0099_MR1',\n",
    "            'OAS2_0100_MR1',\n",
    "            'OAS2_0101_MR1',\n",
    "            'OAS2_0102_MR1',\n",
    "            'OAS2_0103_MR1',\n",
    "            'OAS2_0104_MR1',\n",
    "            'OAS2_0105_MR1',\n",
    "            'OAS2_0106_MR1',\n",
    "            'OAS2_0108_MR1',\n",
    "            'OAS2_0109_MR1',\n",
    "            'OAS2_0111_MR1',\n",
    "            'OAS2_0112_MR1',\n",
    "            'OAS2_0113_MR1',\n",
    "            'OAS2_0114_MR1',\n",
    "            'OAS2_0116_MR1',\n",
    "            'OAS2_0117_MR1',\n",
    "            'OAS2_0118_MR1',\n",
    "            'OAS2_0119_MR1',\n",
    "            'OAS2_0120_MR1',\n",
    "            'OAS2_0121_MR1',\n",
    "            'OAS2_0122_MR1',\n",
    "            'OAS2_0124_MR1',\n",
    "            'OAS2_0126_MR1',\n",
    "            'OAS2_0127_MR1',\n",
    "            'OAS2_0128_MR1',\n",
    "            'OAS2_0129_MR1',\n",
    "            'OAS2_0131_MR1',\n",
    "            'OAS2_0133_MR1',\n",
    "            'OAS2_0134_MR1',\n",
    "            'OAS2_0135_MR1',\n",
    "            'OAS2_0137_MR1',\n",
    "            'OAS2_0138_MR1',\n",
    "            'OAS2_0139_MR1',\n",
    "            'OAS2_0140_MR1',\n",
    "            'OAS2_0141_MR1',\n",
    "            'OAS2_0142_MR1',\n",
    "            'OAS2_0143_MR1',\n",
    "            'OAS2_0144_MR1',\n",
    "            'OAS2_0145_MR1',\n",
    "            'OAS2_0146_MR1',\n",
    "            'OAS2_0147_MR1',\n",
    "            'OAS2_0149_MR1',\n",
    "            'OAS2_0150_MR1',\n",
    "            'OAS2_0152_MR1',\n",
    "            'OAS2_0154_MR1',\n",
    "            'OAS2_0156_MR1',\n",
    "            'OAS2_0157_MR1',\n",
    "            'OAS2_0158_MR1',\n",
    "            'OAS2_0159_MR1',\n",
    "            'OAS2_0160_MR1',\n",
    "            'OAS2_0161_MR1',\n",
    "            'OAS2_0162_MR1',\n",
    "            'OAS2_0164_MR1',\n",
    "            'OAS2_0165_MR1',\n",
    "            'OAS2_0169_MR1',\n",
    "            'OAS2_0171_MR1',\n",
    "            'OAS2_0172_MR1',\n",
    "            'OAS2_0174_MR1',\n",
    "            'OAS2_0175_MR1',\n",
    "            'OAS2_0176_MR1',\n",
    "            'OAS2_0177_MR1',\n",
    "            'OAS2_0178_MR1',\n",
    "            'OAS2_0179_MR1',\n",
    "            'OAS2_0181_MR1',\n",
    "            'OAS2_0182_MR1',\n",
    "            'OAS2_0183_MR1',\n",
    "            'OAS2_0184_MR1',\n",
    "            'OAS2_0185_MR1',\n",
    "            'OAS2_0186_MR1'\n",
    "        ]\n",
    "\n",
    "scan_filenames = np.asarray(list(map(lambda x: data_prefix + x + \"/\" + image_postfix, scan_filenames)))\n",
    "\n",
    "csv_data = np.recfromcsv('/Users/justinchang/Desktop/Cs168/CS168/oasis_longitudinal_filtered.csv')\n",
    "\n",
    "# note that we have to filter out the non MR1 scans.\n",
    "\n",
    "status = np.asarray([True if x.decode() == 'Demented' else False for x in csv_data['group']])\n",
    "assert(len(scan_filenames) == len(status))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#csv_data = np.recfromcsv('/Users/justinchang/Desktop/Cs168/CS168/oasis_longitudinal.csv')\n",
    "#age = np.asarray([100. if x.decode() == 'Nondemented' else 1. if x.decode() == 'Demented' else 50. for x in csv_data['group'][:len(gray_matter_map_filenames)]])\n",
    "\n",
    "# Comparisons to recfromcsv data must be/Users/RichardMin/nilearn_data/oasis2/oasis_longitudinal.csv bytes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data\n",
    "----------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: '/Volumes/Elements/OAS2_RAW_PART1/OAS2_0100_MR1/RAW/mpr-1.nifti.img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-326294e55834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     memory='nilearn_cache')  # cache options\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscans_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnifti_masker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscan_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nilearn/input_data/base_masker.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, confounds, **fit_params)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 return self.fit(X, **fit_params\n\u001b[0m\u001b[1;32m    204\u001b[0m                                 ).transform(X, confounds=confounds)\n\u001b[1;32m    205\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nilearn/input_data/nifti_masker.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, imgs, y)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[%s.fit] Computing the mask\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             self.mask_img_ = self._cache(compute_mask, ignore=['verbose'])(\n\u001b[0;32m--> 232\u001b[0;31m                 imgs, verbose=max(0, self.verbose - 1), **mask_args)\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_niimg_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m                           \u001b[0;34m'directory %s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                         % (name, argument_hash, output_dir))\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0;31m# Memmap the output at the first call to be consistent with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persist_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36mcompute_background_mask\u001b[0;34m(data_imgs, border_size, connected, opening, target_affine, target_shape, memory, verbose)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Background mask computation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     \u001b[0mdata_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;31m# Delayed import to avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    266\u001b[0m             return _iter_check_niimg(niimg, ensure_ndim=ensure_ndim,\n\u001b[1;32m    267\u001b[0m                                      dtype=dtype)\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mconcat_niimgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;31m# We check the dimensionality of the niimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDimensionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;31m# Keep track of the additional dimension in the error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: '/Volumes/Elements/OAS2_RAW_PART1/OAS2_0100_MR1/RAW/mpr-1.nifti.img'"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "nifti_masker = NiftiMasker(\n",
    "    standardize=False,\n",
    "    smoothing_fwhm=2,\n",
    "    memory='nilearn_cache')  # cache options\n",
    "\n",
    "scans_masked = nifti_masker.fit_transform(scan_filenames)\n",
    "\n",
    "\n",
    "#segment the data\n",
    "\n",
    "train_ratio = 0.8\n",
    "validation_ratio = 0.0\n",
    "test_ratio = 0.2\n",
    "\n",
    "assert(train_ratio + validation_ratio + test_ratio == 1)\n",
    "\n",
    "zipped_data = list(zip(scans_masked, status))\n",
    "random.shuffle(zipped_data)\n",
    "\n",
    "shuffled_scans, shuffled_status = zip(*zipped_data)\n",
    "\n",
    "train_scans = shuffled_scans[:int(len(shuffled_scans) * train_ratio)]\n",
    "validation_scans = shuffled_scans[int(len(shuffled_scans) * train_ratio):int(len(shuffled_scans) * (train_ratio + validation_ratio))]\n",
    "test_scans = shuffled_scans[int(len(shuffled_scans) * (train_ratio + validation_ratio)):]\n",
    "train_status = shuffled_status[:int(len(shuffled_status) * train_ratio)]\n",
    "validation_status = shuffled_status[int(len(shuffled_status) * train_ratio):int(len(shuffled_status) * (train_ratio + validation_ratio))]\n",
    "test_status = shuffled_status[int(len(shuffled_status) * (train_ratio + validation_ratio)):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction pipeline with ANOVA and RandomForestClassifier\n",
    "---------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA + SVR\n"
     ]
    }
   ],
   "source": [
    "print(\"ANOVA + SVR\")\n",
    "# Define the prediction function to be used.\n",
    "# Here we use a Support Vector Classification, with a linear kernel\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "#svc = SVC(kernel='linear')\n",
    "# number of forests is 10, the max depth of tree is how deep it goes in terms of # of leaves? and features is # of features to consider per split\n",
    "RFC=RandomForestClassifier(max_depth=5, n_estimators=10, max_features=3)\n",
    "#weight function used in prediction. Possible values:\n",
    "#‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "#‘distance’ : weight points by the inverse of their distance. \n",
    "#in this case, closer neighbors of a query point will have \n",
    "#a greater influence than neighbors which are further away.\n",
    "\n",
    "\n",
    "# Dimension reduction\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, \\\n",
    "        f_regression\n",
    "\n",
    "# Remove features with too low between-subject variance\n",
    "variance_threshold = VarianceThreshold(threshold=.01)\n",
    "\n",
    "# Here we use a classical univariate feature selection based on F-test,\n",
    "# namely Anova.\n",
    "feature_selection = SelectKBest(f_regression, k=2000)\n",
    "\n",
    "# We have our predictor (SVR), our feature selection (SelectKBest), and now,\n",
    "# we can plug them together in a *pipeline* that performs the two operations\n",
    "# successively:\n",
    "from sklearn.pipeline import Pipeline\n",
    "anova_RFC = Pipeline([\n",
    "            ('variance_threshold', variance_threshold),\n",
    "            ('anova', feature_selection),\n",
    "            ('RandomForestClassifier', RFC)])\n",
    "\n",
    "### Fit and predictscans_masked\n",
    "anova_RFC.fit(train_scans, train_status)\n",
    "status_pred = anova_RFC.predict(test_scans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization\n",
    "--------------\n",
    "Look at the SVR's discriminating weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinchang/.local/lib/python3.6/site-packages/nilearn/plotting/__init__.py:20: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2909, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-9e3324102725>\", line 1, in <module>\n",
      "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2131, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-107>\", line 2, in matplotlib\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3051, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/Users/justinchang/anaconda3/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n",
      "/Users/justinchang/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/justinchang/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANOVA ===\n",
      "Prediction accuracy: -0.502144\n",
      "\n",
      "Massively univariate model\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "print(\"Accuracy: \" + str(sklearn.metrics.accuracy_score(test_status, status_pred)))\n",
    "print(\"Precision: \" + str(sklearn.metrics.precision_score(test_status, status_pred)))\n",
    "print(\"Recall: \" + str(sklearn.metrics.recall_score(test_status, status_pred)))\n",
    "print(\"F1: \" + str(sklearn.metrics.f1_score(test_status, status_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
