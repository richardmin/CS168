{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Voxel-Based Morphometry on Oasis dataset\n",
    "========================================\n",
    "\n",
    "This example uses Voxel-Based Morphometry (VBM) to study the relationship\n",
    "between aging and gray matter density.\n",
    "\n",
    "The data come from the `OASIS <http://www.oasis-brains.org/>`_ project.\n",
    "If you use it, you need to agree with the data usage agreement available\n",
    "on the website.\n",
    "\n",
    "It has been run through a standard VBM pipeline (using SPM8 and\n",
    "NewSegment) to create VBM maps, which we study here.\n",
    "\n",
    "Predictive modeling analysis: VBM bio-markers of aging?\n",
    "--------------------------------------------------------\n",
    "\n",
    "We run a standard SVM-ANOVA nilearn pipeline to predict age from the VBM\n",
    "data. We use only 100 subjects from the OASIS dataset to limit the memory\n",
    "usage.\n",
    "\n",
    "Note that for an actual predictive modeling study of aging, the study\n",
    "should be ran on the full set of subjects. Also, parameters such as the\n",
    "smoothing applied to the data and the number of features selected by the\n",
    "Anova step should be set by nested cross-validation, as they impact\n",
    "significantly the prediction score.\n",
    "\n",
    "Brain mapping with mass univariate\n",
    "-----------------------------------\n",
    "\n",
    "SVM weights are very noisy, partly because heavy smoothing is detrimental\n",
    "for the prediction here. A standard analysis using mass-univariate GLM\n",
    "(here permuted to have exact correction for multiple comparisons) gives a\n",
    "much clearer view of the important regions.\n",
    "\n",
    "____\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Elvis Dhomatob, <elvis.dohmatob@inria.fr>, Apr. 2014\n",
    "#          Virgile Fritsch, <virgile.fritsch@inria.fr>, Apr 2014\n",
    "#          Gael Varoquaux, Apr 2014\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "n_subjects = 2  # more subjects requires more memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Oasis dataset\n",
    "-------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OAS30001': [['/Users/RichardMin/CS168/files/OAS30001_MR_d0129/anat3/sub-OAS30001_sess-d0129_run-02_T1w.nii.gz', '/Users/RichardMin/CS168/files/OAS30001_MR_d0129/anat2/sub-OAS30001_sess-d0129_run-01_T1w.nii.gz'], ['/Users/RichardMin/CS168/files/OAS30001_MR_d0757/anat3/sub-OAS30001_sess-d0757_run-02_T1w.nii.gz', '/Users/RichardMin/CS168/files/OAS30001_MR_d0757/anat2/sub-OAS30001_sess-d0757_run-01_T1w.nii.gz']]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import configparser\n",
    "import json\n",
    "import csv\n",
    "from nilearn import plotting\n",
    "from enum import Enum, auto\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# parse in config to see where to read the files in from\n",
    "\n",
    "DementiaStrings = [\"AD dem/FLD prior to AD dem\", \n",
    "                    \"AD dem w/depresss  not contribut\", \n",
    "                    \"AD dem w/depresss- not contribut\", \n",
    "                    \"AD dem w/Frontal lobe/demt at onset\", \n",
    "                    \"Incipient demt PTP\", \n",
    "                    \"AD dem w/oth (list B) not contrib\", \n",
    "                    \"AD dem distrubed social- prior\", \n",
    "                    \"Vascular Demt  primary\", \n",
    "                    \"AD dem Language dysf with\", \n",
    "                    \"AD dem distrubed social- with\", \n",
    "                    \"DAT\", \n",
    "                    \"DLBD- secondary\", \n",
    "                    \"DAT w/depresss not contribut\", \n",
    "                    \"Frontotemporal demt. prim\", \n",
    "                    \"AD dem Language dysf after\", \n",
    "                    \"AD dem w/CVD not contrib\", \n",
    "                    \"AD dem w/oth unusual features\", \n",
    "                    \"AD dem w/PDI after AD dem not contrib\", \n",
    "                    \"AD dem w/oth (list B) contribut\", \n",
    "                    \"AD dem cannot be primary\", \n",
    "                    \"AD dem Language dysf prior\", \n",
    "                    \"AD dem visuospatial- prior\", \n",
    "                    \"AD dem w/oth unusual features/demt on\", \n",
    "                    \"AD dem w/depresss- contribut\", \n",
    "                    \"AD dem w/CVD contribut\", \n",
    "                    \"AD dem visuospatial- with\", \n",
    "                    \"DLBD- primary\", \n",
    "                    \"Incipient Non-AD dem\", \n",
    "                    \"Dementia/PD- primary\", \n",
    "                    \"AD dem distrubed social- after\", \n",
    "                    \"Vascular Demt- secondary\", \n",
    "                    \"AD dem w/depresss  contribut\", \n",
    "                    \"AD Dementia\", \n",
    "                    \"AD dem w/PDI after AD dem contribut\", \n",
    "                    \"AD dem w/oth unusual feat/subs demt\", \n",
    "                    \"Vascular Demt- primary\"]\n",
    "NoDementiaStrings = [\"ProAph w/o dement\", \n",
    "                        \"Non AD dem- Other primary\", \n",
    "                        \"Cognitively normal\", \n",
    "                        \"No dementia\"]\n",
    "class Dementia(Enum):\n",
    "    DEMENTIA = \"Dementia\"\n",
    "    NO_DEMENTIA = \"No_Dementia\"\n",
    "    UNKNOWN = \"Unknown\"\n",
    "\n",
    "    @staticmethod\n",
    "    def from_str(string):\n",
    "        if string in DementiaStrings:\n",
    "            return Dementia.DEMENTIA\n",
    "        elif string in NoDementiaStrings:\n",
    "            return Dementia.NO_DEMENTIA\n",
    "        return Dementia.UNKNOWN\n",
    "\n",
    "\n",
    "patient_results = {}\n",
    "with open('../patient_diagnosis.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    headers = next(reader)\n",
    "    for row in reader:\n",
    "        rowObj = {}\n",
    "        for h, v in zip(headers, row):\n",
    "            rowObj[h] = v\n",
    "        if rowObj['Subject'] not in patient_results:\n",
    "            patient_results[rowObj['Subject']] = []\n",
    "        patient_results[rowObj['Subject']].append(rowObj)\n",
    "\n",
    "patient_id_to_results = {}\n",
    "for subject, subjectData in patient_results.items():\n",
    "    for data in subjectData:\n",
    "        if data['dx1'] is '':\n",
    "            continue\n",
    "        if subject not in patient_id_to_results:\n",
    "            patient_id_to_results[subject] = [Dementia.from_str(data['dx1'])]\n",
    "        else:\n",
    "            patient_id_to_results[subject].append(Dementia.from_str(data['dx1']))\n",
    "\n",
    "\n",
    "for subject, data in patient_id_to_results.items():\n",
    "    if len(data) is 1:\n",
    "        patient_id_to_results[subject] = data[0]\n",
    "    elif len(data) > 1 and len(set(data)) != 1:\n",
    "        if Dementia.DEMENTIA in data:\n",
    "            patient_id_to_results[subject] = Dementia.DEMENTIA\n",
    "        elif Dementia.NO_DEMENTIA in data:\n",
    "            patient_id_to_results[subject] = Dementia.NO_DEMENTIA\n",
    "        else:\n",
    "            patient_id_to_results[subject] = Dementia.UNKNOWN\n",
    "    else:\n",
    "        patient_id_to_results[subject] = data[0]\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "location = config['FILES']['Location']\n",
    "\n",
    "# find all the files in the folder\n",
    "raw_scan_ids = [x for x in os.listdir(location)]\n",
    "if '.DS_Store' in raw_scan_ids: raw_scan_ids.remove('.DS_Store')\n",
    "\n",
    "id_extractor_pattern = re.compile('(.*?)_')\n",
    "\n",
    "labelled_scan_ids = []\n",
    "\n",
    "for raw_scan_id in raw_scan_ids:\n",
    "    m = id_extractor_pattern.match(raw_scan_id)\n",
    "    scan_id = m.group(1)\n",
    "    if scan_id not in patient_id_to_results:\n",
    "        continue\n",
    "    elif patient_id_to_results[scan_id] is Dementia.UNKNOWN:\n",
    "        continue\n",
    "    labelled_scan_ids.append((scan_id, raw_scan_id))\n",
    "\n",
    "FLAG = \"T1w\" #or T2w\n",
    "mri_extractor_pattern = re.compile('anat[0-9]*')\n",
    "\n",
    "if FLAG is \"T1w\":\n",
    "    mri_type_pattern = re.compile(\".*T1w.nii.gz\")\n",
    "else:\n",
    "    mri_type_pattern = re.compile(\".*T2w.nii.gz\")\n",
    "\n",
    "paths = {}\n",
    "\n",
    "\n",
    "for scan_id, raw_scan_id in labelled_scan_ids:\n",
    "    raw_scan_id = location + \"/\" + raw_scan_id\n",
    "    scans = [x for x in os.listdir(raw_scan_id) if mri_extractor_pattern.match(x)]\n",
    "    scanLocations = []\n",
    "    for scan in scans:\n",
    "        scan_folder = raw_scan_id + \"/\" + scan\n",
    "        scanTypeMatch = [x for x in os.listdir(scan_folder) if mri_type_pattern.match(x)]\n",
    "        if scanTypeMatch:\n",
    "            scanLocations.append(scan_folder + \"/\" + scanTypeMatch[0])\n",
    "    if scan_id not in paths:\n",
    "        paths[scan_id] = []\n",
    "    paths[scan_id].append(scanLocations)\n",
    "print(paths)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti(fname):\n",
    "        nifti_obj = nib.load(fname)\n",
    "        nifti_data = nifti_obj.get_data()#.astype(dtype)\n",
    "        return nifti_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/RichardMin/CS168/files/OAS30001_MR_d0129/anat3/sub-OAS30001_sess-d0129_run-02_T1w.nii.gz', '/Users/RichardMin/CS168/files/OAS30001_MR_d0129/anat2/sub-OAS30001_sess-d0129_run-01_T1w.nii.gz', '/Users/RichardMin/CS168/files/OAS30001_MR_d0129/anat3/sub-OAS30001_sess-d0129_run-02_T1w.nii.gz', '/Users/RichardMin/CS168/files/OAS30001_MR_d0129/anat2/sub-OAS30001_sess-d0129_run-01_T1w.nii.gz', '/Users/RichardMin/CS168/files/OAS30001_MR_d0757/anat3/sub-OAS30001_sess-d0757_run-02_T1w.nii.gz', '/Users/RichardMin/CS168/files/OAS30001_MR_d0757/anat2/sub-OAS30001_sess-d0757_run-01_T1w.nii.gz', '/Users/RichardMin/CS168/files/OAS30001_MR_d0757/anat3/sub-OAS30001_sess-d0757_run-02_T1w.nii.gz', '/Users/RichardMin/CS168/files/OAS30001_MR_d0757/anat2/sub-OAS30001_sess-d0757_run-01_T1w.nii.gz']\n",
      "asdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#load oasis dataset \n",
    "\n",
    "#oasis_dataset = datasets.paths(n_subjects=n_subjects)\n",
    "\n",
    "#age = oasis_dataset.ext_vars['age'].astype(float)\n",
    "#print(gray_matter_map_filenames)\n",
    "#print(oasis_dataset)\n",
    "# print basic information on the dataset\n",
    "#print('First gray-matter anatomy image (3D) is located at: %s' %\n",
    " #     oasis_dataset.gray_matter_maps[0])  # 3D data\n",
    "#print('First white-matter anatomy image (3D) is located at: %s' %\n",
    " #     oasis_dataset.white_matter_maps[0])  # 3D data\n",
    "    \n",
    "path_string = []\n",
    "\n",
    "for personId, MRISession in paths.items():\n",
    "\n",
    "    for MRI in sorted(MRISession):\n",
    "        for scan in sorted(MRI):\n",
    "            path_string = path_string + list(MRI) \n",
    "        \n",
    "\n",
    "print(path_string)\n",
    "\n",
    "for personId, MRISession in paths.items():\n",
    "    print('asdf')\n",
    "    for MRI in sorted(MRISession):\n",
    "        for scan in sorted(MRI):\n",
    "            img = nib.load(scan)\n",
    "           # print('Mask nifti image (3D) is located at (Note this is definitely not a \"mast nifti image\", was playing around with img.get_data(): %s' % img.get_data())\n",
    "           # print(scan) #this is the actual location of the data\n",
    "        pass\n",
    "    \n",
    "    \n",
    "filenames=path_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 256, 256)\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "(176, 256, 256)\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "(176, 256, 256)\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "(176, 256, 256)\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "(176, 256, 256)\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "(176, 256, 256)\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "(176, 256, 256)\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "(176, 256, 256)\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Field of view of image #1 is different from reference FOV.\nReference affine:\narray([[  9.96810973e-01,  -1.34100309e-02,   7.87301585e-02,\n         -8.90206375e+01],\n       [  7.32105831e-03,   9.96994495e-01,   7.71253705e-02,\n         -1.08050598e+02],\n       [ -7.95282051e-02,  -7.63026252e-02,   9.93908048e-01,\n         -1.46887207e+02],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          1.00000000e+00]])\nImage affine:\narray([[  9.96803343e-01,  -1.34120397e-02,   7.87297711e-02,\n         -8.90189972e+01],\n       [  7.32100848e-03,   9.96992528e-01,   7.71507844e-02,\n         -1.08053558e+02],\n       [ -7.95275569e-02,  -7.63279647e-02,   9.93906140e-01,\n         -1.46883850e+02],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          1.00000000e+00]])\nReference shape:\n(176, 256, 256)\nImage shape:\n(176, 256, 256, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-701d95cab1a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtransformed_nib_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgm_maps_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnifti_masker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# print(gm_maps_masked.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# n_samples, n_features = gm_maps_masked.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nilearn/input_data/base_masker.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, confounds, **fit_params)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 return self.fit(X, **fit_params\n\u001b[0m\u001b[1;32m    204\u001b[0m                                 ).transform(X, confounds=confounds)\n\u001b[1;32m    205\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nilearn/input_data/nifti_masker.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, imgs, y)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[%s.fit] Computing the mask\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             self.mask_img_ = self._cache(compute_mask, ignore=['verbose'])(\n\u001b[0;32m--> 232\u001b[0;31m                 imgs, verbose=max(0, self.verbose - 1), **mask_args)\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_niimg_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36mcompute_background_mask\u001b[0;34m(data_imgs, border_size, connected, opening, target_affine, target_shape, memory, verbose)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Background mask computation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     \u001b[0mdata_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;31m# Delayed import to avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    266\u001b[0m             return _iter_check_niimg(niimg, ensure_ndim=ensure_ndim,\n\u001b[1;32m    267\u001b[0m                                      dtype=dtype)\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mconcat_niimgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m    462\u001b[0m     for index, (size, niimg) in enumerate(izip(lengths, _iter_check_niimg(\n\u001b[1;32m    463\u001b[0m             \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matleast_4d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_fov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_fov\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             memory=memory, memory_level=memory_level))):\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36m_iter_check_niimg\u001b[0;34m(niimgs, ensure_ndim, atleast_4d, target_fov, dtype, memory, memory_level, verbose)\u001b[0m\n\u001b[1;32m    157\u001b[0m                         \u001b[0;34m\"Reference shape:\\n%r\\nImage shape:\\n%r\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                         % (i, ref_fov[0], niimg.affine, ref_fov[1],\n\u001b[0;32m--> 159\u001b[0;31m                            niimg.shape))\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDimensionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Field of view of image #1 is different from reference FOV.\nReference affine:\narray([[  9.96810973e-01,  -1.34100309e-02,   7.87301585e-02,\n         -8.90206375e+01],\n       [  7.32105831e-03,   9.96994495e-01,   7.71253705e-02,\n         -1.08050598e+02],\n       [ -7.95282051e-02,  -7.63026252e-02,   9.93908048e-01,\n         -1.46887207e+02],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          1.00000000e+00]])\nImage affine:\narray([[  9.96803343e-01,  -1.34120397e-02,   7.87297711e-02,\n         -8.90189972e+01],\n       [  7.32100848e-03,   9.96992528e-01,   7.71507844e-02,\n         -1.08053558e+02],\n       [ -7.95275569e-02,  -7.63279647e-02,   9.93906140e-01,\n         -1.46883850e+02],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          1.00000000e+00]])\nReference shape:\n(176, 256, 256)\nImage shape:\n(176, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "#preprocess data\n",
    "nifti_masker = NiftiMasker(\n",
    "    standardize=False,\n",
    "    smoothing_fwhm=2,\n",
    "    memory='nilearn_cache')  # cache options\n",
    "\n",
    "transformed_nib_images = []\n",
    "for filename in filenames:\n",
    "    image = nib.load(filename)\n",
    "    print(image.shape)\n",
    "    print(type(image))\n",
    "    transformed_nib_images.append(image)\n",
    "    pass\n",
    "# gm_maps_masked = nifti_masker.fit_transform(filenames)\n",
    "# print(gm_maps_masked.shape)\n",
    "# n_samples, n_features = gm_maps_masked.shape\n",
    "# print(\"%d samples, %d features\" % (n_subjects, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
